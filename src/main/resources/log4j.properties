lgd.application.logging.dir = C:/Users/Consulente/ProjectFileSystem/log/lgd_scala
lgd.application.logging.filename = ${lgd.application.logging.dir}/lgd_scala.log
lgd.application.logging.appender.layout = org.apache.log4j.PatternLayout
lgd.application.logging.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} [%p] %C.%M: %m%n

# APPENDERS
# stdout
log4j.appender.stdout = org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Threshold = INFO
log4j.appender.stdout.Target = System.out
log4j.appender.stdout.layout = ${lgd.application.logging.appender.layout}
log4j.appender.stdout.layout.ConversionPattern = ${lgd.application.logging.layout.pattern}

# rolling_file
log4j.appender.rolling_file = org.apache.log4j.RollingFileAppender
log4j.appender.rolling_file.Threshold = INFO
log4j.appender.rolling_file.append = true
log4j.appender.rolling_file.File = ${lgd.application.logging.filename}
log4j.appender.rolling_file.layout = ${lgd.application.logging.appender.layout}
log4j.appender.rolling_file.layout.ConversionPattern = ${lgd.application.logging.layout.pattern}
log4j.appender.rolling_file.MaxFileSize = 1MB
log4j.appender.rolling_file.MaxBackupIndex = 5

# LOGGERS
log4j.rootLogger = INFO, stdout, rolling_file
log4j.logger.it.carloni.luca = INFO, stdout, rolling_file
log4j.logger.org.apache.hadoop = INFO, rolling_file
log4j.logger.org.apache.spark = INFO, rolling_file
log4j.logger.org.spark_project.jetty = WARN, rolling_file

# avoids Windows-related errors when ShutdownHookManager
# attempts to delete spark temporary working directory
log4j.logger.org.apache.spark.util.ShutdownHookManager = OFF
log4j.logger.org.apache.spark.SparkEnv = ERROR

# LOGGER ADDITIVITY
log4j.additivity.org.apache.hadoop = false
log4j.additivity.org.apache.spark = false
log4j.additivity.it.carloni.luca = false
log4j.additivity.org.spark_project.jetty = false
